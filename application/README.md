# Прокси сервер

## Как запустить
Для запуска необходимо установить `rust` и `cargo`.

Далее запустить в командной строке:
```shell
cd server
cargo run -q -- <server_port> <concurrency_level>
```

## Комментарии
В процессе отладки меня видимо забанил гугл, поэтому `http://www.google.com/` перенаправляет на версию сайта с SSL. А в проксе я не смог обработку SSL настроить, поэтому сайты `https://` могут не открываться, как и то, куда меня перенаправляет гугол. Там начинается бесконечный редирект, поэтому после 10 редиректов прокси возвращает последний полученный ответ. Хром такой ответ превращает в приглашение к редиректу прямо в браузере, мозилла сама автоматом редиректит.

При вводе сайтов необходимо указывать `http://` или (если повезет) `https://`, без этого выдаст ошибку. То есть ввести в поисковую строку браузера `http:/127.0.0.1:8080/e-maxx.ru/` не выйдет, надо `http:/127.0.0.1:8080/http://e-maxx.ru/`.

Логи записываются в отдельные файлы `proxy_session_*.log` для каждой сессии. В названии файла и самих логах используется время с начала UNIX эпохи в секундах. В логи пишется время запроса, его метод, статус ответа, url и аргумент (у некоторых сайтов аргумент никак не связан с url).

Черный список с сайтами находится в файле `blacklist.json`, url к ним тоже необходимо указывать с протоколом в префиксе. В черный список вносится как сам указанный сайт, так и все его дочерние.

Информация о закешированных сайтах хранится в `cache_meta.json`, сами данные закешированных сайтов хранятся в папке `cache`. Файлы туда складываются по `etag` сайта из http ответов с этих сайтов. При сохранении файла в кеш и попадании запроса в него в консоль выведется сообщение.

Метаданные (все) о закешированных сайтах перезаписываются в файл `cache_meta.json` после каждого взаимодействия с кешом. Чтение файла один раз во время работы сервера при его запуске. Сами закешированные сайты (пере)записываются при получении этого данных сайта.

Вообще в условии написано возвращать закешированный сайт без соединения с сервером, но это как будто не всегда правильно. Некоторые сайты не прикладывают хедер `Cache-control`, который отвечает за период, в течение которого данные в кеше будут актуальны. Поэтому в любом случае необходимо создавать соединение с веб-сервером как минимум для отправки условного `GET` запроса, и если на него пришел ответ `304 Not Modified` (который не содержит тела), то можно вернуть с прокси закешированное значение. Если файл в кеше прокис, то придет ответ с другим статусом и телом, и в зависимости от них, уже можно действовать по-другому.

Важно, если это `GET` запрос не на документ, ставить в конце url слеш, так как файлы со стилем могут не подтянуться (браузер резолвит пути для рекурсивных запросов через изначальный url, на стороне прокси это не отслеживается, так как сайты могут хранить стили по-разному: у себя в папке или на другом сайте). То есть вместо `http://127.0.0.1:8080/http://httpforever.com` нужно указывать `http://127.0.0.1:8080/http://httpforever.com/`.
